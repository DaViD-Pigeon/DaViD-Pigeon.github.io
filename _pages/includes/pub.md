
# üìù Publications
*#* denotes co-first authors

## üéô Singing Voice Synthesis
<div class='paper-box'>
    <div class='paper-box-image'>
        <div>
            <div class="badge">NeurIPS 2024(Spotlight)</div>
            <img src='../../images/gtsinger.png' alt="sym" width="100%"></div>
        </div>
        <div class='paper-box-text' markdown="1">

[GTSinger: A Global Multi-Technique Singing Corpus with Realistic Music Scores for All Singing Tasks](http://papers.nips.cc/paper_files/paper/2024/hash/023d2c1a17cf35b11a0cbb43a0677c91-Abstract-Datasets_and_Benchmarks_Track.html) \\
Yu Zhang, **Changhao Pan***#*, Wenxiang Guo*#*, et al.

[![](https://img.shields.io/github/stars/GTSinger/GTSinger?style=social&label=Project+Stars)](https://github.com/GTSinger/GTSinger) [![Hugging Face](https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-blue?label=Dataset)](https://huggingface.co/datasets/GTSinger/GTSinger) [**Demo**](https://gtsinger.github.io)

- GTSinger is a large Global, multi-Technique, free-to-use, high-quality singing corpus with realistic music scores, designed for all singing tasks.
- Our work is promoted by multiple media and forums, such as [![weixin](https://img.shields.io/badge/-WeChat@Êú∫Âô®‰πãÂøÉ-000000?logo=wechat&logoColor=07C160)](https://mp.weixin.qq.com/s/B1Iqr-24l57f0MslzYEslA), [![weixin](https://img.shields.io/badge/-WeChat@PaperWeekly-000000?logo=wechat&logoColor=07C160)](https://mp.weixin.qq.com/s/6RLdUzJM5PItklKUTTNz2w), and [![zhihu](https://img.shields.io/badge/-Áü•‰πé-000000?logo=zhihu&logoColor=0084FF)](https://zhuanlan.zhihu.com/p/993933492).

</div>
</div>

<div class='paper-box'>
    <div class='paper-box-image'>
        <div>
            <div class="badge">ACL 2025(Findings)</div>
            <img src='../../images/stars.png' alt="sym" width="100%"></div>
        </div>
        <div class='paper-box-text' markdown="1">

[STARS: A Unified Framework for Singing Transcription, Alignment, and Refined Style Annotation]() \\
Wenxiang Guo#, Yu Zhang#, **Changhao Pan**#, et al.

[**Project**](https://demo-stars.github.io/)   
- STARS is a unified framework for singing transcription, alignment, and refined style annotation based on hierarchical representation learning.
</div>
</div>

<div class='paper-box'>
    <div class='paper-box-image'>
        <div>
            <div class="badge">ACL 2025(Findings)</div>
            <img src='../../images/tcsinger2.png' alt="sym" width="100%"></div>
        </div>
        <div class='paper-box-text' markdown="1">

[TCSinger 2: Customizable Multilingual Zero-shot Singing Voice Synthesis](https://arxiv.org/abs/2505.14910) \\
Yu Zhang#, Wenxiang Guo#, **Changhao Pan**#, et al.

[**Project**](https://aaronz345.github.io/TCSinger2Demo/) \| [![](https://img.shields.io/github/stars/AaronZ345/TCSinger2?style=social&label=TCSinger2+Stars)](https://github.com/AaronZ345/TCSinger2) 
- TCSinger 2 is a multi-task multilingual zero-shot SVS model with style transfer and style control based on various prompts.
</div>
</div>

- `EMNLP-2024` [TCSinger: Zero-Shot Singing Voice Synthesis with Style Transfer and Multi-Level Style Control](https://arxiv.org/abs/2409.15977v2), Yu Zhang, Ziyue Jiang, Ruiqi Li, **Changhao Pan**, Jinzheng He, Rongjie Huang, Chuxin Wang, Zhou Zhao.

- `AAAI-2025` [TechSinger: Technique Controllable Multilingual Singing Voice Synthesis via Flow Matching](), Wenxiang Guo, Yu Zhang, **Changhao Pan**, et. al. 

## üëÇ Spatial Audio

<div class='paper-box'>
    <div class='paper-box-image'>
        <div>
            <div class="badge">ACM-MM 2025</div>
            <img src='../../images/mesa.png' alt="sym" width="100%"></div>
        </div>
        <div class='paper-box-text' markdown="1">

[A Multimodal Evaluation Framework for Spatial Audio Playback Systems: From Localization to Listener Preference]() \\
**Changhao Pan**#, Wenxiang Guo, Yu Zhang, et al.

[![Hugging Face](https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-blue?label=Dataset)]() [**Project**](https://david-pigeon.github.io/mesa-demo/) 
- PSA-MOS provides 50 hours of high-quality spatial audio recordings, with detailed localization annotations and fine-grained MOS ratings.
- MESA is a multimodal evaluation framework for spatial audio playback systems which exhibits strong correlation with human perceptual assessments.
</div>
</div>

<div class='paper-box'>
    <div class='paper-box-image'>
        <div>
            <div class="badge">ACM-MM 2025</div>
            <img src='../../images/isdrama.png' alt="sym" width="100%"></div>
        </div>
        <div class='paper-box-text' markdown="1">

[ISDrama: Immersive Spatial Drama Generation through Multimodal Prompting](https://arxiv.org/abs/2504.20630) \\
Yu Zhang#, Wenxiang Guo#, **Changhao Pan**#, et al.

[![Hugging Face](https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-blue?label=Dataset)]() [**Project**](https://aaronz345.github.io/ISDramaDemo/) 
- MRSDrama is the first multimodal recorded spatial drama dataset, containing binaural drama audios, scripts, videos, geometric poses, and textual prompts. 
- ISDrama is the first immersive spatial drama generation model through multimodal prompting.
</div>
</div>

## üéº Music Generation

<div class='paper-box'>
    <div class='paper-box-image'>
        <div>
            <div class="badge">Preprint</div>
            <img src='../../images/versband.png' alt="sym" width="100%"></div>
        </div>
        <div class='paper-box-text' markdown="1">

[Versatile Framework for Song Generation with Prompt-based Control](https://arxiv.org/abs/2504.19062) \\
Yu Zhang#, Wenxiang Guo#, **Changhao Pan**#, et al.

[**Project**](https://aaronz345.github.io/VersBandDemo/) 
- VersBand is a multi-task song generation framework for synthesizing high-quality, aligned songs with prompt-based control. 
</div>
</div>

<div class='paper-box'>
    <div class='paper-box-image'>
        <div>
            <div class="badge">Submitted to NeurIPS 2025</div>
            <img src='../../images/mrsaudio.png' alt="sym" width="100%"></div>
        </div>
        <div class='paper-box-text' markdown="1">

[]() \\
Wenxiang Guo*#*, **Changhao Pan***#*, Zhiyuan Zhu*#*, Xintong Hu*#*, et al.

[![Hugging Face](https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-blue?label=Dataset)]() [**Demo**](https://mrsaudio.github.io/)

- The **largest recorded spatial audio dataset** contains four scenarios: daily life, singing, music, and speech, with a total duration of **500 hours**.
- Supports **multiple spatial audio tasks**: audio spatialization, spatial TTA, acoustic event localization and detection(SELD), etc.
</div>
</div>

## Others
- ``IEEE-TVCG`` [Interactive Table Synthesis with Natural Language](https://ieeexplore.ieee.org/document/10304286), Yanwei Huang, Yunfan Zhou, Ran Chen, **Changhao Pan**, Xinhuan Shu, Di Weng, Yingcai Wu.